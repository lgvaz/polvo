{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc542ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp classification.baseline.baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d9fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.vision.all import *\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d9229e",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "> Quick baselines to compare your model results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ff8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class FastaiMetricWrapper(GetAttr):\n",
    "    _default = 'metric'\n",
    "    def __init__(self, metric):\n",
    "        self.metric = metric\n",
    "        \n",
    "    def accumulate(self, pred, yb):\n",
    "        fake_learner = namedtuple('FakeLearner', 'pred yb y to_detach')(pred, (yb,), yb, to_detach)\n",
    "        self.metric.accumulate(fake_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8fb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def calculate_metrics(dl, metrics, probs_func, n_classes=None):\n",
    "    \"Calculate metrics for a baseline method `probs_func`\"\n",
    "    n_classes = n_classes or get_c(dl)\n",
    "    if n_classes == 0:\n",
    "        raise ValueError(\"Couldn't automatically infer number of classes from dataloader. Please explicitly specify it with `n_classes`\")\n",
    "        \n",
    "    metrics = L(metrics).map(compose(mk_metric, FastaiMetricWrapper))\n",
    "    for metric in metrics: metric.reset()\n",
    "\n",
    "    for x,y in dl:\n",
    "        pred = probs_func(x, y, n_classes)\n",
    "        for metric in metrics: metric.accumulate(pred, y)\n",
    "\n",
    "    return {metric.name: metric.value for metric in metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df8d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(10, 1)\n",
    "Y = tensor([0, 1, 3, 2, 0, 1, 1, 0, 0, 2])\n",
    "\n",
    "dl = TfmdDL(TensorDataset(X, Y), bs=4)\n",
    "\n",
    "x, y = first(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "582e15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: calculate_metrics(dl, None, None), contains='classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e1934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =  [accuracy, error_rate, F1Score(average='macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c9a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fixed_probs(x, y, n_classes, class_id):\n",
    "    pred = torch.zeros(find_bs(y), n_classes).to(y.device)\n",
    "    pred[:, class_id] = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41d2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = fixed_probs(x, y, 4, 1)\n",
    "\n",
    "test_eq(pred, tensor([[0., 1., 0., 0.],\n",
    "                      [0., 1., 0., 0.],\n",
    "                      [0., 1., 0., 0.],\n",
    "                      [0., 1., 0., 0.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79f825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = calculate_metrics(dl, metrics, partial(fixed_probs, class_id=2), 3)\n",
    "test_eq(res, {'accuracy': 0.2000, 'error_rate': 0.8000, 'f1_score': 0.08333333333333334})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5e24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def random_probs(x, y, n_classes):\n",
    "    pred = torch.randn(find_bs(y), n_classes).to(y.device)\n",
    "    pred = torch.nn.functional.softmax(pred, dim=-1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1dbc181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1449, 0.2503, 0.1713, 0.4335],\n",
       "        [0.3958, 0.2078, 0.1248, 0.2716],\n",
       "        [0.3533, 0.3805, 0.1470, 0.1192],\n",
       "        [0.1083, 0.5671, 0.0373, 0.2873]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_probs(x, y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddcfcb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': TensorBase(0.3000),\n",
       " 'error_rate': TensorBase(0.7000),\n",
       " 'f1_score': 0.2361111111111111}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(dl, metrics, random_probs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccebe762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't make much sense? Because when probs are converted to preds with `argmax` the first one will always be picked\n",
    "# def uniform_probs(x, y, n_classes):\n",
    "#     pred = torch.ones(find_bs(y), n_classes).to(y.device)\n",
    "#     pred /= n_classes\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab10bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = uniform_probs(x, y, 4)\n",
    "# test_eq(pred, tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
    "#                       [0.2500, 0.2500, 0.2500, 0.2500],\n",
    "#                       [0.2500, 0.2500, 0.2500, 0.2500],\n",
    "#                       [0.2500, 0.2500, 0.2500, 0.2500]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6beda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aa5d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
